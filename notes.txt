general workflow:
- parse deb|dsc files and check integrity (add-based operations)
- download Releases file and check download integrity? (or perform a list operation)
- download various Packages/Sources files and check download integrity
- append deb|dsc control information to respective Packages/Sources list
- generate Packages/Sources/Release files
- upload deb|dsc|tar.gz files to pool (overwriting anything already there...) (add-based operations)
- upload Packages/Sources/Release[.gpg] files


actual package name/version/architecture is our unique, primary key: http://www.aptly.info/doc/feature/duplicate/
adding a duplicate package will indicate it was skipped, exit code 0
version should be required for remove/link/unlink. It can be a specific version or "all"
  implicit behavior based upon version is too vague and therefore likely to have significant and undesirable consequences


bundle = a set of packages with the same version, e.g. liveaddress-streetapi
all files that are part of a bundle must all have the same version


// this CLI is needs some attention. It allows to much room for error with s3 paths+dist+category
raptr
   add /path/to/set/of/related/files/all/with/same/version to "s3://bucket-name/dir/dir/dir distribution category"
   remove [package-name] [version] from "s3://bucket-name/dir/dir/dir distribution category"
   link [package-name] [version] from "s3://bucket-name/dir/dir/dir distribution category" to "distribution category"
   unlink [package-name] [version] from "s3://bucket-name/dir/dir/dir distribution category"
   purge "s3://bucket-name/dir/dir/dir" # must scan for all Packages and Sources files along with entire pool directory


deb-s3 (ruby) is a good approach, but doesn't support concurrency, source packages, or the standard pool structure
it also has a ton of runtime dependencies we don't want


The following directory structure makes it easy to find a particular bundle and all files related to it for things
like linking and removing. it's also really easy to discover all files that exist as part of a particular bundle.
Pool directory structure: /pool/category/(first letter of bundle)/(bundle name)/(version)/bundle files here


during remove operations, I like the idea of removing bundles (based upon name) as well as removing specific files
based upon the filename (pkg name+verion+arch). only deb's and dsc's can be removed. orig.tar.gz can't be removed
the orig.tar.gz will be nuked during the next purge/sweep/vacuum operation.


What good is the Releases file in each distribution during normal operations? The only reason we might use it
is to discover what Packages|Sources files exist. Thus far, it doesn't appear to be helping us much.


Priorities:
[Now] DEB/DSC file parsing and integrity checks
[Soon?] Release file parsing (to find all Sources|Packages files)
[Soon] Sources|Packages file parsing (to identify all packages and filenames in a distribution)
[Soon] Compression--just use gzip
[Soon] Various hashes, e.g. MD5, SHA1, SHA256?
[Later] Delete behavior (for package bundles and individual files)
[Later] Sweep/Purge/Clean behavior
   (needs to download the Release file for each distribution and parse it
    so that it knows which pool files are in use and which are not
[Last] Release.gpg generation
[Last] Command line interface
[Future] Link and unlink to/from distribution (for package bundles and individual files)
[Future] DryRun

link/unlink operations are tricky because we're crossing distribution boundaries
we're reading from at least TWO different sets of Release+Sources|Packages files
(even though we're using the same pool) and then we're linking them together
we could perform a LIST command at the root of the repo to get a list of all categories
and then get the Release file and finally the Sources|Packages file for each
we need a higher level of abstraction called Distribution that
understands what/how that can work with a backend to get a Release file
and then gets the various Sources|Releases files and parses and understands them
and we can use those to add/remove packages/files to them
(and perhaps they can verify the integrity of the deb|dsc) files that are added?
(perhaps a Distribution instance can verify the integrity of the added files?)
