type UploadItem struct {
	Path string
	MD5 string
	Contents io.Reader
}

// why not have the max timeout, max attempts, and check-if-exists options something handled by the backend for all items
type S3UploadItem {
	Path string
	MD5 string
	Contents io.Reader
	MaxAttempts int
	MaxTimeout time.Duration
	CheckIfExists bool
} 

Upload() blocks until all files have been successfully uploaded (using wait groups)
does Upload() return []UploadResult?
filename, result, reason, e.g.

Download(items []DownloadItem) []DownloadResult // preserve ordering; blocks until all downloads have completed

type DownloadItem struct {
	Path string
	MD5 []byte // empty = don't verify
}
type DownloadResult struct {
	Path string
	Err error
	Contents io.Reader
}

Errors resulting from download:
1. nil / success
2. content mismatch (after N attempts, the contents didn't match the expected)
3. 404 not found / doesn't exist
4. permissions
5. remote/backend system unavailable

type UploadResult struct {
	Request UploadItem
	Err error
}

Errors resulting from upload:
1. nil / success
2. content mismatch (after N upload attempts, the contents didn't match the expected according to the server)
3. concurrency mismatch--the version of the file has changed since it was last seen
	(future: concurrency is future, but we could easily have some kind of "protect concurrency" option on uploads
	 such that we check prior to upload (via HEAD) if the file has changed and after the file has been written
	 if it has changed. if not, we're good to go.)
4. permissions
5. remote/backend system unavailable

concurrency notes: if ANY file has changed, restart the entire process from download, update indexes, upload

type Remote interface() {
	Put([]UploadRequest) []UploadResult
	Get([]DownloadRequest) []DownloadResult
	Delete([]DeleteRequest) []DeleteResult
}

// overlay to speed up download, but then during upload concurrency issues will occur
// when it sees a concurrency issue during upload, it invalids the local, cached copy
type CachedRemote struct {}
type S3Remote struct {}

We could manage the concurrency at a different level, e.g. Remote interface: Put/Get/Delete which are naturally blocking
at the same time, by batching the operations, we can manage the concurrency at a different level, e.g.
using a ton of go routines and wait groups. we can also leverage our own http transport for things like keep-alive, etc.
realistically, we're talking about downloading about 4-5 files and then re-uploading those 4-5 files along with perhaps
4-5 more deb|dsc files


---------------------------------------------------------------------------

type PutRequest struct {
	Path string
	MD5 []byte
	SizeInBytes uint64
	Contents io.Reader (so we can stream large files from the fs; or we can wrap []byte slices)
	ConsistencyModel int (Chaos, ConditionalPut, ReadYourWrite)
						HeadBefore or HeadAfter? VerifyBeforeWrite, VerifyAfterWrite?
	OverwriteMode: Always, SkipOnDuplicateName, SkipOnDuplicateMD5
}

type GetResponse struct {
	Created time.Time
	Modified time.Time?
	MD5 []byte
	SizeInBytes uint64
	Error error (contains not found errors, etc.)
}

type Remote interface {
	List(ListRequest) ListResponse
	Head(HeadRequest) HeadResponse
	Put(PutRequest) PutResponse
	Get(GetRequest) GetResponse
	Delete(DeleteRequest) DeleteResponse
}

Implementations:
Batch/Bulk/ParallelRemote (different interface that uses batch semantics, e.g. []ListRequest -> []ListResult)
	receives an array of requests, and calls calls "go innerRemote..."
	then waits on the responses and puts the various responses into an ordered array
CachedRemote
	has two remotes a "local" remote and a true/actual remote
	for Get requests it checks the local copy first
	it watches responses and any concurrency issues invalidate the local item
	any local items that are 404 are sent to the actual remote
Local/FileSystemRemote
	a local implementation based upon a configured directory
ConcurrentRemote
	enforces the consistency model on the request by performing a HEAD request
	before and after the request as desired
	skips PUT where the MD5 hasn't changed (with chaos concurrency model); if MD5 hasn't changed,
	  skips upload but will check MD5 using VerifyAfterUpload/Pessemistic head request
RetryRemote
	watches for connection-related errors and performs a retry on the item up to N times
S3Remote
	communicates with S3 and performs the actual/desired behavior
	(this is the most important one because without it, we have no remote)
	(could possibly utilize a connection pool of HTTP transports as a perf optimization)

Priorities:
[Now] DEB file parsing and integrity checks
[Now] DSC file parsing and integrity checks (for DSC and all related files)
[Soon] Release file parsing (to find all Sources|Packages files)
[Soon] Sources|Packages file parsing (to identify all packages and filenames in a distribution)
[Soon] Compression--just use gzip or try xz?
[Last] Release.gpg generation
[Last] Command line interface
[Soon] Various hashes, e.g. MD5, SHA1, SHA256?
[Later/Future?] Link and unlink to/from distribution (for package bundles and individual files)
[Later] Delete behavior (for package bundles and individual files)
	(needs to download the Release file for each distribution and parse it
 	 so that it knows which pool files are in use and which are not
[Later] Sweep/Purge/Clean behavior
[Future] DryRun

link/unlink is a bit more difficult because we're crossing distribution boundaries
we're reading from at least TWO different sets of Release+Sources|Packages files
(even though we're using the same pool) and then we're linking them together
we could perform a LIST command at the root of the repo to get a list of all categories
and then get the Release file and finally the Sources|Packages file for each
we need a higher level of abstraction called Distribution that
understands what/how that can work with a backend to get a Release file
and then gets the various Sources|Releases files and parses and understands them
and we can use those to add/remove packages/files to them
(and perhaps they can verify the integrity of the deb|dsc) files that are added?
(perhaps a Distribution instance can verify the integrity of the added files?)
